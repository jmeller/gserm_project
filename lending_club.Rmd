---
title: 'Project Report: Default Predictions for Lending Club'
author: Jochen Hartmann and Jan Meller
output:
  html_document:
    df_print: paged
---

# Problem overview

# Data loading
```{r data_loading, results = "hide"}
library(data.table)
library(randomForest)
library(ranger)
library(magrittr)
library(caret)
library(dplyr)
library(tidyverse)

# features not to use
# taboo.list <- c("last_fico_range_high", "last_fico_range_low", "acc_now_delinq")

train.raw <- fread("lending_club_train.csv", stringsAsFactors = T)
test.raw <- fread("lending_club_test.csv", stringsAsFactors = T)
```

# Data cleaning
```{r data_cleaning}
# combine train and test data for data handling
data.raw <- union(
  # the mutate function adds a source so we can split it again later
  train.raw[, data_source := "train"],
  test.raw[, `:=`(data_source = "test",
                  default = as.integer(default))]
)

# clean/transform features
data.raw %<>% .[,`:=`(title = factor(title),
                      home_ownership = factor(home_ownership),
          revol_util = as.numeric(str_replace_all(revol_util, "[%]", "")),
          term = factor(term),
          default = factor(default, 
                           levels = c("0","1"), 
                           labels = c("no_default", "default")))]

# clean memory
rm(train.raw, test.raw)
```

# Explorative data analysis (EDA)
```{r EDA 1}
summary(data.raw) # explore data using standard summary function
```

```{r EDA 1}
library(visdat)

# explore data
vis_dat(data.raw[1,], sort_type = T) # explore distribution of data types
sum(unlist(lapply(data.raw, function(x) is.numeric(x))))/ncol(data.raw) # compute share of numeric variables

# detect outliers
tukey_outliers <- function (x) {

  Q1 <- quantile(x, 1/4, na.rm = TRUE)
  Q3 <- quantile(x, 3/4, na.rm = TRUE)
  IQR <- Q3 - Q1

  # note: need to exclude NA values
  outliers <- unique(x[!is.na(x) & (x < Q1 - 1.5 * IQR | x > Q3 + 1.5 * IQR)])
  return(outliers)
}

# count number of outliers per numeric variable and store as numeric_outliers
numeric_vars <- unname(unlist(lapply(data.raw, function(x) is.numeric(x))))
numeric_outliers <- lapply(data.raw[,which(numeric_vars), with = F], function(x) tukey_outliers(x))
summary(numeric_outliers)

# store names of outliers
df <- which(lapply(numeric_outliers, length) > 10000)
names(df)

# visually inspect "fico_range_low" w/ boxplot
boxplot(data.raw[,c("fico_range_low")], main = "Fico Range Low")

# select only those outliers
selected_numeric_vars <- data.raw[,names(df), with = F]
summary(selected_numeric_vars)

# create new binary outlier columns
data.outliers <- data.raw[,.(id, revol_bal, tot_cur_bal, avg_cur_bal, bc_open_to_buy, tot_hi_cred_lim, total_bal_ex_mort, total_il_high_credit_limit)]
data.outliers$revol_bal_outlier <- selected_numeric_vars$revol_bal %in% tukey_outliers(selected_numeric_vars$revol_bal)
data.outliers$tot_cur_bal_outlier <- selected_numeric_vars$tot_cur_bal %in% tukey_outliers(selected_numeric_vars$tot_cur_bal)
data.outliers$avg_cur_bal_outlier <- selected_numeric_vars$avg_cur_bal %in% tukey_outliers(selected_numeric_vars$avg_cur_bal)
data.outliers$bc_open_to_buy_outlier <- selected_numeric_vars$bc_open_to_buy %in% tukey_outliers(selected_numeric_vars$bc_open_to_buy)
data.outliers$tot_hi_cred_lim_outlier <- selected_numeric_vars$tot_hi_cred_lim %in% tukey_outliers(selected_numeric_vars$tot_hi_cred_lim)
data.outliers$total_bal_ex_mort_outlier <- selected_numeric_vars$total_bal_ex_mort %in% tukey_outliers(selected_numeric_vars$total_bal_ex_mort)
data.outliers$total_il_high_credit_limit_outlier <- selected_numeric_vars$total_il_high_credit_limit %in% tukey_outliers(selected_numeric_vars$total_il_high_credit_limit)
data.outliers %<>% .[,!c("revol_bal", "tot_cur_bal", "avg_cur_bal", "bc_open_to_buy", "tot_hi_cred_lim", "total_bal_ex_mort", "total_il_high_credit_limit")]
```

# Missing value handling
```{r missing value handling}
# divide data set into subsets w. numeric and categorical data
col.classes <- sapply(data.raw, class)
num.features <- which(col.classes %in% c("numeric", "integer"))
cat.features <- c(1, which(col.classes %in% c("factor", "logical", "character")))
data.num.features <- data.raw[,num.features, with = F]
data.cat.features <- data.raw[,cat.features, with = F]
# exclude cols with less than 2 categories
cat.levels <- data.cat.features[,lapply(.SD, function(col) length(unique(col)))] %>% unlist
excl.cats <- which(cat.levels < 2)
data.cat.features %<>% .[,!excl.cats, with = F] %>% .[,!"default", with = F]

# cat features: replace NA w. "Missing"
data.cat.features %<>% 
  .[,lapply(.SD, function(col) ifelse(is.na(col), "Missing", as.character(col)))] %>%
  .[,id := as.numeric(id)]

# numeric features
fill.rates.num <- data.num.features[,lapply(.SD, 
                               function(col) sum(1 - as.integer(is.na(col)))/nrow(data.num.features)), 
                       .SDcols = names(data.num.features)] %>% unlist
## remove cols with > 75% missing data
cols.wNAs.num <- fill.rates.num[which(fill.rates.num > 0.75)]
data.wNAs.num <- data.num.features[, c(names(cols.wNAs.num)), with = F]

## impute NAs by means
impute.cols <- names(data.wNAs.num)[which(!names(data.wNAs.num) == "id")]
data.wNAs.num <- data.wNAs.num[,paste0("dmi_", impute.cols) := # add dmis
                           lapply(.SD, function(col) ifelse(is.na(col), 1, 0)),
                         .SDcols = impute.cols]
data.imputed.num <- data.wNAs.num[,(impute.cols) := 
                              lapply(.SD, function(col) 
                                ifelse(is.na(col), mean(col, na.rm = T), col)), 
                            .SDcols = impute.cols]
## scale cols - only "truly" numeric ones
scale.cols <- names(data.imputed.num) %>% .[-which(str_detect(., "id|dmi_"))]
data.imputed.num %<>% .[,(scale.cols) := lapply(.SD, scale), .SDcols = scale.cols]

# merge back
target <- data.raw[,.(id, default)]
data.preprocessed <- merge(data.cat.features, data.imputed.num, by = "id") %>% 
  merge(target, by = "id") %>% merge(data.outliers, by = "id")
```
# Feature engineering
```{r feature engineering}
# feature engineering
data.preprocessed %<>% .[,`:=`(emp_title = as.factor(ifelse(str_detect(tolower(emp_title), "manager|director|ceo"),
                                                 "executive",
                                                 ifelse(str_detect(tolower(emp_title), "engineer|specialist"),
                                                        "specialist",
                                                        "other"))),
                        last_credit_pull_d_month = as.factor(str_sub(last_credit_pull_d, 1,3)),
                        last_credit_pull_d_year = as.factor(str_sub(last_credit_pull_d, 5,8)),
                        last_credit_pull_d = NULL,
                        earliest_cr_line_month = as.factor(str_sub(earliest_cr_line, 1,3)),
                        earliest_cr_line_year = str_sub(earliest_cr_line, 5,8),
                        earliest_cr_line = NULL,
                        zip_2 = as.factor(str_sub(zip_code, 1, 2)))] %>%
  .[,`:=`(length_bs_rel = (2018 - as.integer(earliest_cr_line_year)),
          earliest_cr_line_year = as.factor(earliest_cr_line_year),
          zip_code = NULL, term = as.factor(term),
          emp_length = as.factor(emp_length),
          home_ownership = as.factor(home_ownership),
          desc = NULL,
          purpose = as.factor(purpose),
          title = as.factor(title),
          addr_state = as.factor(addr_state),
          initial_list_status = as.factor(initial_list_status),
          application_type = as.factor(application_type),
          verification_status_joint = as.factor(verification_status_joint))]
```

# Feature selection
```{r feature_selection}
train <- data.preprocessed[data_source == "train"] %>% .[,!which(names(.) %in%
                                                                   c("id", "data_source")),
                                                         with = F]
# train <- train[data_source == "train"] %>% .[,!which(names(.) %in% 
#                                                                    c("id", "data_source")), 
#                                                          with = F]
fit <- ranger(default ~ ., train, importance = "impurity", num.trees = 20)
importance.feat <- importance(fit) %>% .[order(., decreasing = T)]
importance.feat

top20.feat <- names(importance.feat)[1:20]
top20.feat

# manual.feat <- c("acc_now_delinq", "delinq_amnt", "fico_range_low", 
#                  "num_tl_30dpd", "pct_tl_nvr_dlq", "revol_util")
# 
# final.feat <- union(top10.feat, manual.feat)
final.feat <- top20.feat
```
# Model tuning and evaluation
```{r evaluation}
library(caret)
set.seed(2608)

# train.data_set
train <- data.preprocessed[data_source == "train"] %>% .[,!which(names(.) %in% 
                                                                   c("id", "data_source")), 
                                                         with = F] 
train.data.all <- train[, c("default", final.feat), with = F]
train.data.subset <- train.data.all[sample(1:nrow(train), 5000)]

# create the caret experiment using the trainControl() function
ctrl <- trainControl(
  method = "cv", number = 10, # 10-fold CV
  selectionFunction = "best", # select the best performer
  classProbs = TRUE, # requested the predicted probs (for ROC)
  summaryFunction = twoClassSummary, # needed to produce the ROC/AUC measures
  savePredictions = TRUE # needed to plot the ROC curves
)

# random forest model
if(!file.exists("m.ranger.rds")) {
  
  ranger.grid <- expand.grid(mtry = c(4,5), splitrule = "gini", min.node.size = 1)
  # train actual model
  m.ranger <- train(default ~ .,
                    data = train.data.all,
                    method = "ranger",
                    metric = "ROC",
                    trControl = ctrl, 
                    tuneGrid = ranger.grid, verbose = T,
                    num.trees = 100) # 500
  
  m.ranger
  saveRDS(m.ranger, "m.ranger.rds")
} else {
  m.ranger <- readRDS("m.ranger.rds")
} 

# boosted tree model
if(!file.exists("m.xgboost.rds")) {
  xgb.grid <- expand.grid(nrounds = c(50, 100, 150), 
                          max_depth = 6, eta = 0.3, 
                          subsample = 1, colsample_bytree = 1, 
                          gamma = 0, min_child_weight = 1)
  # train actual model
  m.xgboost <- train(default ~.,
                     data = train.data.all,
                     method = "xgbTree",
                     metric = "ROC",
                     tuneGrid = xgb.grid,
                     trControl = ctrl, verbose = T)
  
  m.xgboost
  saveRDS(m.xgboost, "m.xgboost.rds")
  
} else {
  m.xgboost <- readRDS("m.xgboost.rds")
}
# # legacy code: directly learn xgboost model
# library(xgboost)
# library(forcats)
# library(dummies)
#   X_train <- train.data.all %>%
#     dplyr::select(-default) %>% dummy.data.frame(verbose = T, drop = F) %>%
#     as.matrix()
#   y_train <- train.data.all$default %>% recode(no_default = 0, default = 1)
#     
#   # XGB ---------------------------------------------------------------------
#   param <- list("objective" = "binary:logistic", #binary:logistic
#                 "eval_metric" = "auc",
#                 "eta" = 0.01,
#                 "max_depth" = 7)
#   
#   cv.nfold <- 5
#   
#  m.xgb <- xgb.cv(param = param,
#                 data = X_train,
#                 label = y_train,
#                 nfold = cv.nfold,
#                 nrounds = 100)
# 
#  # best nrounds param:
#  xgb.final <- xgboost(param = param,
#                   data = X_train,
#                   label = y_train,
#                   nrounds = 100,
#                   verbose = 1)
```

# Performance evaluation
```{r performance evaluation}
# collect resamples
results <- resamples(list(XGB=m.xgboost, RF=m.ranger))

# summarize the distributions
summary(results)

# boxplots of results
bwplot(results)

# dot plots of results
dotplot(results)
```

```{r make final predictions}
test <- data.preprocessed[data_source == "test"] %>% .[,!which(names(.) == "data_source"), with = F]
test$P_default <- predict(m.ranger, test, type = "prob")$default
final.predictions <- test[,.(id, P_default)] %>% as.data.frame
write_csv(final.predictions, "6.csv")

# # for xgb
# X_test <- test %>%
#   .[,top20.feat, with = F] %>% dummy.data.frame(verbose = T, drop = F) %>%
#     as.matrix()
# test.xgb <- test
# test.xgb$P_default <- predict(xgb.final, X_test, type= "prob")
# final.predictions.xgb <- test.xgb[,.(id, P_default)] %>% as.data.frame
# write_csv(final.predictions.xgb, "6_xgb_experimental.csv")
```